{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3: MCMC\n",
    "### Jake Pitkin\n",
    "**CS 6190: Probabilistic Modeling - Spring 2018**<br>\n",
    "**April 7 2018**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$1.$ Write a function to perform Gibbs sampling of a binary label image $x$ with the Ising model prior and iid Gaussian likelihood, given a noisy image $y$. This function should take $\\alpha$, $\\beta$, and $\\sigma$ parameters, and generate a random binary image (labels in the set $\\{-1,1\\}$ according to the posterior Gibbs distribution for $x|y.$ The energy should look like this:\n",
    "\n",
    "$$U(x) = -\\alpha \\sum_{i} x_i - \\beta \\sum_{\\langle i,j\\rangle} x_ix_j + \\frac{1}{2\\sigma^2} \\sum_{i} (x_i - y_i)^2$$\n",
    "\n",
    "Note this is assuming that the $x_i$ labels are also the mean pixel values in the Gaussian. The $\\alpha$ parameter controls the proportion of labels that are $-1$ versus $+1$. Negative values of $\\alpha$ will favor more $-1$ pixels, and positive values of $\\alpha$ will favor more $+1$ pixels.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from PIL import Image\n",
    "\n",
    "IMAGE_WIDTH = None\n",
    "IMAGE_HEIGHT = None\n",
    "Y = None\n",
    "X = None\n",
    "\n",
    "def read_image(path):\n",
    "    global IMAGE_WIDTH, IMAGE_HEIGHT, Y, X\n",
    "    img = Image.open(path, 'r').convert('RGB')\n",
    "    pixels = img.load()\n",
    "    IMAGE_WIDTH = img.size[0]\n",
    "    IMAGE_HEIGHT = img.size[1]\n",
    "    Y = [[pixels[x,y] for x in range(IMAGE_WIDTH)] for y in range(IMAGE_HEIGHT)]\n",
    "    X = [[0 for x in range(IMAGE_WIDTH)] for y in range(IMAGE_HEIGHT)]\n",
    "    print(pixels[0,0])\n",
    "    \n",
    "def get_neighbours(row, col):\n",
    "    # left, right, up, and down initialized to wrap values\n",
    "    neighbours = [X[row][IMAGE_WIDTH-1], X[row][0], X[IMAGE_HEIGHT-1][col], X[0][col]]\n",
    "    # check if we don't have to wrap and replace\n",
    "    if col != 0: # left\n",
    "        neighbours[0] = X[row][col-1]\n",
    "    if col != IMAGE_WIDTH-1: #right\n",
    "        neighbours[1] = X[row][col+1]\n",
    "    if row != 0: #up\n",
    "        neighbours[2] = X[row-1][col]\n",
    "    if row != IMAGE_HEIGHT-1:\n",
    "        neighbours[3] = X[row+1][col]\n",
    "    return neighbours\n",
    "\n",
    "def energy(alpha, beta, sigma, row, col):\n",
    "    neighbours = get_neighbours(row, col)\n",
    "    energy = -1 * alpha * X[row][col]\n",
    "    for n in neighbours:\n",
    "        energy -= beta * X[row][col] * n\n",
    "    energy += (1/(2*math.pow(sigma, 2))) * math.pow(X[row][col]-Y[row][col], 2)\n",
    "    return energy\n",
    "\n",
    "def energy_norm(alpha, beta, sigma, row, col, x):\n",
    "    neighbours = get_neighbours(row, col)\n",
    "    energy = -1 * alpha * x\n",
    "    for n in neighbours:\n",
    "        energy -= beta * x * n\n",
    "    energy += (1/(2*math.pow(sigma, 2))) * math.pow(x-Y[row][col], 2)\n",
    "    return energy\n",
    "\n",
    "def cond_dist_single_pixel(alpha, beta, sigma, row, col):\n",
    "    cond_dist = math.exp(-1 * energy(alpha, beta, sigma, row, col))\n",
    "    print(cond_dist)\n",
    "    normalize = math.exp(-1 * energy_norm(alpha, beta, sigma, row, col, 1))\n",
    "    print(normalize)\n",
    "    normalize += math.exp(-1 * energy_norm(alpha, beta, sigma, row, col, -1))\n",
    "    print(normalize)\n",
    "    #return cond_dist / normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a)** Run your code with just the Ising prior term (no posterior). Do this a few times and generate several random binary images. Try different $\\alpha$ and $\\beta$ terms to see what the effects are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(149, 149, 149)\n",
      "(158, 158, 158)\n",
      "(124, 124, 124)\n",
      "(187, 187, 187)\n",
      "(154, 154, 154)\n",
      "(144, 144, 144)\n",
      "(168, 168, 168)\n",
      "(107, 107, 107)\n",
      "(146, 146, 146)\n",
      "(145, 145, 145)\n",
      "(164, 164, 164)\n",
      "(157, 157, 157)\n",
      "(154, 154, 154)\n",
      "(143, 143, 143)\n",
      "(145, 145, 145)\n",
      "(121, 121, 121)\n",
      "(146, 146, 146)\n",
      "(161, 161, 161)\n",
      "(157, 157, 157)\n",
      "(120, 120, 120)\n",
      "(129, 129, 129)\n",
      "(142, 142, 142)\n",
      "(162, 162, 162)\n",
      "(132, 132, 132)\n",
      "(160, 160, 160)\n",
      "(135, 135, 135)\n",
      "(127, 127, 127)\n",
      "(134, 134, 134)\n",
      "(123, 123, 123)\n",
      "(154, 154, 154)\n",
      "(153, 153, 153)\n",
      "(156, 156, 156)\n",
      "(134, 134, 134)\n",
      "(159, 159, 159)\n",
      "(140, 140, 140)\n",
      "(164, 164, 164)\n",
      "(152, 152, 152)\n",
      "(163, 163, 163)\n",
      "(171, 171, 171)\n",
      "(145, 145, 145)\n",
      "(127, 127, 127)\n",
      "(135, 135, 135)\n",
      "(152, 152, 152)\n",
      "(127, 127, 127)\n",
      "(127, 127, 127)\n",
      "(121, 121, 121)\n",
      "(156, 156, 156)\n",
      "(154, 154, 154)\n",
      "(118, 118, 118)\n",
      "(146, 146, 146)\n",
      "(136, 136, 136)\n",
      "(142, 142, 142)\n",
      "(149, 149, 149)\n",
      "(149, 149, 149)\n",
      "(141, 141, 141)\n",
      "(107, 107, 107)\n",
      "(132, 132, 132)\n",
      "(139, 139, 139)\n",
      "(141, 141, 141)\n",
      "(138, 138, 138)\n",
      "(123, 123, 123)\n",
      "(149, 149, 149)\n",
      "(127, 127, 127)\n",
      "(138, 138, 138)\n",
      "(126, 126, 126)\n",
      "(164, 164, 164)\n",
      "(114, 114, 114)\n",
      "(130, 130, 130)\n",
      "(143, 143, 143)\n",
      "(130, 130, 130)\n",
      "(156, 156, 156)\n",
      "(113, 113, 113)\n",
      "(141, 141, 141)\n",
      "(121, 121, 121)\n",
      "(133, 133, 133)\n",
      "(138, 138, 138)\n",
      "(153, 153, 153)\n",
      "(131, 131, 131)\n",
      "(139, 139, 139)\n",
      "(159, 159, 159)\n",
      "(156, 156, 156)\n",
      "(154, 154, 154)\n",
      "(161, 161, 161)\n",
      "(142, 142, 142)\n",
      "(150, 150, 150)\n",
      "(143, 143, 143)\n",
      "(147, 147, 147)\n",
      "(160, 160, 160)\n",
      "(128, 128, 128)\n",
      "(156, 156, 156)\n",
      "(124, 124, 124)\n",
      "(121, 121, 121)\n",
      "(111, 111, 111)\n",
      "(145, 145, 145)\n",
      "(137, 137, 137)\n",
      "(137, 137, 137)\n",
      "(132, 132, 132)\n",
      "(154, 154, 154)\n",
      "(145, 145, 145)\n",
      "(146, 146, 146)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'int' and 'tuple'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-4459afe381f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mread_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"noisy-message.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcond_dist_single_pixel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-76-455192ff4b0f>\u001b[0m in \u001b[0;36mcond_dist_single_pixel\u001b[0;34m(alpha, beta, sigma, row, col)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcond_dist_single_pixel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mcond_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0menergy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mnormalize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0menergy_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-76-455192ff4b0f>\u001b[0m in \u001b[0;36menergy\u001b[0;34m(alpha, beta, sigma, row, col)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mneighbours\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0menergy\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0menergy\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0menergy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'int' and 'tuple'"
     ]
    }
   ],
   "source": [
    "read_image(\"noisy-message.png\")\n",
    "cond_dist_single_pixel(0.5, 0.2, 0.1, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)** Run your code on the images ${\\tt noisy}$-${\\tt message.png}$ and ${\\tt noisy}$-${\\tt yinyang.ong}$. After you read an image, you need to apply the following intensity transform to the pixels (to get black $= -1$ and white $= +1$): \n",
    "\n",
    "$x \\ * \\ 20 \\ - \\ 10$\n",
    "\n",
    "Compute the posterior mean images for both examples (again, don't forget to burn-in). You can fix values for $\\alpha$, $\\beta$, and $\\sigma^2$ (you will want to tune these manually to get something that works well). What values of $\\alpha, \\beta, \\sigma^2$ did you use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c)** Use your posterior samples to iteratively estimate $\\sigma^2$ from the data. That is, assume the \"clean\" image that you sample is the true image, and use it to get an MLE of $\\sigma^2$ (update this estimate each iteration). What final estimate do you get for $\\sigma^2$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$2.$ Say you are given data $(X,Y)$, with $X \\in \\mathbb{R}^d$ and $Y \\in \\{0,1\\}$. The goal is to train a classifier that will predict an unknown class label $\\tilde{y}$ from a new data point $\\tilde{x}$. Consider the following model:\n",
    "\n",
    "$$Y \\sim Ber\\Big(\\frac{1}{1+e^{-X^T\\beta}}\\Big),$$\n",
    "$$\\beta \\sim N(0, \\sigma^2I).$$\n",
    "\n",
    "This is a Bayesian logistic regression model. Your goal is to derive and implement a Hamiltonian Monte Carlo sampler for doing Bayesian inference on $\\beta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a)** Write down the formula for the unormalized posterior of $\\beta|Y$, i.e.,\n",
    "\n",
    "$$p(\\beta|y;x,\\sigma) \\propto \\prod_{i=1}^n p(y_i|\\beta;x_i)p(\\beta;\\sigma)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)** Show that this posterior is proportional to exp($-U(\\beta))$), where\n",
    "\n",
    "$$U(\\beta) = \\sum_{i=1}^n (1 - y_i)x_i^T \\beta + log(1 + e^{-x_i^T \\beta}) + \\frac{1}{2\\sigma^2}||\\beta||^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c)** Implement a Hamiltonian Monte Carlo Routine in Python for sampling from the posterior of $\\beta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d)** Use your code to analyze the ${\\tt iris}$ data in Python, looking only at two species, *versicolor* and *virginica*. The species labels are your $Y$ data, and the four features, petal length and width, sepal length and width, are your $X$ data. Also, add a constant term, i.e., a columns of 1's to your $X$ matrix. Use the first 30 rows for each species as training data and leave out the last $20$ rows for each species as test data (for a total of $60$ training and $40$ testing). Generate samples of $\\beta$ (don't forget to burn-in), and use these to get a prediction, $\\tilde{y}$, of the class labels for the test data. Use your samples to get a Monte Carlo estimate of the posterior predictive probability $p(\\tilde{y}|y)$ for each testing data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(e)** Draw trace plots of your $\\beta$ sequence and histograms (do 1D plots of each four vector components separately)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(f)** Compare this to the true class labels, $y$, and see how well you did by estimating the average error rate, $E[|y - \\tilde{y}|]$ (a.k.a. the zero-one loss). What values of $\\sigma$, $\\epsilon$, and $L$ did you use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
