{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 0\n",
    "### Jake Pitkin\n",
    "**CS 6190: Probabilistic Modeling - Spring 2018**<br>\n",
    "**January 19th 2018**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Let $X$ and $Y$ be continuous, real-valued random variables. Prove the following: \n",
    "\n",
    "    (a) $E[[X|Y]] = E[X]$\n",
    "    \n",
    "    First we will use the hint and apply the definition of expectation for continuous random variables over Y.\n",
    "    \n",
    "    $$\\int_{-\\infty}^{\\infty} E[ X | Y ] \\  p_y(y) \\ dy$$\n",
    "    \n",
    "    Next apply the definition of conditional expectation from the lecture notes.\n",
    "    \n",
    "    $$\\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} x \\ p_x(x \\ | \\ y) \\ dx \\  p_y(y) \\ dy$$\n",
    "    \n",
    "    Using the definition of joint probability density over two random variables $X, Y$ which is $p(x, y) = p(x|y) * p(y)$.\n",
    "    \n",
    "    $$\\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} x \\ p(x,y) \\ dx \\ dy$$\n",
    "    \n",
    "    Now that we have the joint probability density of $X$ and $Y$, we take the marginal density of X from the lecture notes.\n",
    "    \n",
    "    $$\\int_{-\\infty}^{\\infty} x \\ p(x) \\ dx$$\n",
    "    \n",
    "    Finally the definition of expection of a continuous random variable is applied:\n",
    "    \n",
    "    $$\\int_{-\\infty}^{\\infty} x \\ p(x) \\ dx = E[X]$$\n",
    "    \n",
    "    Thus we have shown that $E[[X|Y]] = E[X]$.\n",
    "    <br><br>\n",
    "    \n",
    "    (b) $Var(X) = E[Var(X|Y)] + Var(E[X|Y])$\n",
    "    \n",
    "    For this proof I will be using the expanded definition of variance $Var(x) = E[X^2] - E[X]^2$ which is shown here [wiki](https://en.wikipedia.org/wiki/Variance#Definition).\n",
    "    \n",
    "    Following the hint, we will expand both the terms on the RHS using the above definition of variance. Expanding $E[Var(X|Y)]$:\n",
    "    \n",
    "    $$E[E[X^2|Y] - E[X|Y]^2] + Var(E[X|Y])$$\n",
    "    \n",
    "   And expanding next expanding $Var(E[X|Y])$:\n",
    "   \n",
    "   $$E[E[X^2|Y] - E[X|Y]^2] + E[E[X|Y]^2] - E[E[X|Y]]^2$$\n",
    "   \n",
    "   Next we will use the linearity of expectation from the lecture notes to get two like terms we can cancel out:\n",
    "   \n",
    "   $$E[E[X^2|Y]] - E[E[X|Y]^2] + E[E[X|Y]^2] - E[E[X|Y]]^2$$\n",
    "   \n",
    "   Canceling out like terms:\n",
    "   \n",
    "   $$E[E[X^2|Y]] - E[E[X|Y]]^2$$\n",
    "   \n",
    "   Finally we apply the result from part (a) to both parts of the equation:\n",
    "   \n",
    "   $$E[X^2] - E[X]^2$$\n",
    "   \n",
    "   This matches the expanded definition of $Var(x)$\n",
    "   \n",
    "   $$Var(x) = E[X^2] - E[X]^2$$\n",
    "   \n",
    "   Thus we have shown that $Var(X) = E[Var(X|Y)] + Var(E[X|Y])$. <br><br>\n",
    "   \n",
    "2. Consider random variables $X$ and $Y$ with joint pdf\n",
    "$$\\begin{equation*}\n",
    "p(x, y) =\n",
    "\\begin{cases}\n",
    "x + y \\qquad &\\text{for $0 \\leq x \\leq 1$, and $0 \\leq y \\leq 1$}\\\\\n",
    "0\\qquad &\\text{otherwise}\n",
    "\\end{cases}\n",
    "\\end{equation*}$$\n",
    "\n",
    "    (a) What is the marginal pdf $p(x)$?\n",
    "    \n",
    "    From the lecture notes the marginal pdf of $X$ is given by: \n",
    "    \n",
    "    $$p(x) = \\int_{a}^{b} p(x, y) \\ dy$$\n",
    "    \n",
    "    Applying this to our case to get the marginal pdf $p(x)$:\n",
    "    \n",
    "    $$p(x) = \\int_{0}^{1} x + y \\ dy$$\n",
    "    \n",
    "    $$p(x) = x * \\frac{y^2}{2} \\Big|_0^1$$\n",
    "    \n",
    "    $$\\boxed{p(x) = \\frac{x}{2}, \\ \\ \\ \\ 0 \\leq x \\leq 1}$$\n",
    "    \n",
    "    <br>\n",
    "    \n",
    "    (b) What is the conditional pdf $p(y | x)$?\n",
    "    \n",
    "    Given two random variables $X$ and $Y$, the conditional pdf is given by:\n",
    "    \n",
    "    $$p(y | x) = \\frac{p(y, x)}{p(x)}$$\n",
    "    \n",
    "    We are given $p(y, x)$ (same as $p(x, y)$) and we solved for $p(x)$ in part (a). Putting it together:\n",
    "    \n",
    "    $$p(y | x) = \\frac{x + y}{\\frac{x}{2}}$$\n",
    "    \n",
    "    $$\\boxed{p(y | x) = \\frac{2(x + y)}{x}, \\ \\ \\ \\ 0 \\leq x \\leq 1, \\ \\ 0 \\leq y \\leq 1}$$\n",
    "    \n",
    "    <br>\n",
    "    \n",
    "    (c) What is the conditional expectation $E[Y | X]$?\n",
    "    \n",
    "    Given two random variables $X$ and $Y$ where $X = x$, the conditional expectation is given by: \n",
    "    \n",
    "    $$E[Y | X = x] = \\int_{-\\infty}^{\\infty} y \\ p(y|x) \\ dy$$\n",
    "    \n",
    "    Using $p(y|x)$ from part (b), we can solve for $E[Y | X = x]$:\n",
    "    \n",
    "    $$E[Y | X = x] = \\int_{0}^{1} \\frac{2y(x+y)}{x} \\ dy$$\n",
    "    \n",
    "    $$E[Y | X = x] = 2 \\int_{0}^{1} \\frac{yx+ y^2}{x} \\ dy$$\n",
    "    \n",
    "    $$E[Y | X = x] = 2 * \\frac{\\frac{xy^2}{2} + \\frac{y^3}{3}}{x} \\Big|_0^1$$\n",
    "    \n",
    "    $$E[Y | X = x] = 2 * \\frac{\\frac{x}{2} + \\frac{1}{3}}{x}$$\n",
    "    \n",
    "    $$\\boxed{E[Y | X = x] = \\frac{x + \\frac{2}{3}}{x}, \\ \\ \\ \\ 0 \\leq x \\leq 1}$$\n",
    "    \n",
    "    <br>\n",
    "\n",
    "    (d) What is the covariance $Cov(X, Y)$?\n",
    "    \n",
    "    From the lecture notes the covariance of two random variables $X$ and $Y$ is given by:\n",
    "    \n",
    "    $$Cov(X, Y) = E[XY] - E[X]E[Y]$$\n",
    "    \n",
    "    We will solve for the three parts and put it together. First, we will solve for $E[XY]$ which is given by:\n",
    "    \n",
    "    $$E[XY] = \\int_{0}^{1} \\int_{0}^{1} xy \\ p(x, y) \\ dx  \\ dy$$\n",
    "    \n",
    "    $$E[XY] = \\int_{0}^{1} \\int_{0}^{1} x^2y + xy^2 \\ dx \\ dy$$\n",
    "    \n",
    "    Integrate by x first from 0 to 1 followed by integrating by y from 0 to 1:\n",
    "    \n",
    "    $$E[XY] = \\int_{0}^{1} \\frac{y}{3} + \\frac{y^2}{2} \\ dy$$\n",
    "    \n",
    "    $$E[XY] = \\frac{1}{3}$$\n",
    "    \n",
    "    Next we will solve for $E[X]$ using $p(x)$ from part (a):\n",
    "    \n",
    "    $$E[X] = \\int_{0}^{1} x \\ p(x) \\ dx$$\n",
    "    \n",
    "    $$E[X] = \\int_{0}^{1} \\frac{x^2}{2} dx$$\n",
    "    \n",
    "    $$E[X] = \\frac{1}{6}$$\n",
    "    \n",
    "    To solve for $E[Y]$ we need $p(y)$:\n",
    "    \n",
    "    $$p(y) = \\int_{0}^{1} x + y \\ dx$$\n",
    "    \n",
    "    $$p(y) = \\frac{y}{2}$$\n",
    "    \n",
    "    Then we solve for $E[Y]$:\n",
    "    \n",
    "    $$E[Y] = \\int_{0}^{1} y \\ p(y) \\ dx$$\n",
    "    \n",
    "    $$E[Y] = \\int_{0}^{1} \\frac{y^2}{2} dx$$\n",
    "    \n",
    "    $$E[Y] = \\frac{1}{6}$$\n",
    "    \n",
    "    Finally we put it all together to get $Cov(X, Y)$:\n",
    "    \n",
    "    $$Cov(X, Y) = E[XY] - E[X]E[Y]$$\n",
    "    \n",
    "    $$Cov(X, Y) = \\frac{1}{3} - \\frac{1}{36}$$\n",
    "    \n",
    "    $$\\boxed{Cov(X, Y) = \\frac{11}{36}, \\ \\ \\ \\ 0 \\leq x \\leq 1, \\ \\ 0 \\leq y \\leq 1}$$\n",
    "    \n",
    "    <br>\n",
    "    \n",
    "3. Let $X \\sim Exp(\\lambda)$, i.e., the exponential distribution with pdf\n",
    "$p(x) = \\lambda \\exp(-\\lambda x)$. Let $Y = \\sqrt{X}$.\n",
    "\n",
    "    (a) What is the density function $p(y)$?\n",
    "    \n",
    "    To determine $p(y)$, we will transform the random variable $X$ to $Y$ using the transformation function $f(x) = \\sqrt{x}$. A requirement is $f(x)$ must be a one-to-one function, which it is. We will use the transformation technique from the lecture notes:\n",
    "    \n",
    "    $$p_y(y) = p_x(f^{-1}(y)) \\ \\mid \\frac{d}{dy} (f^{-1}(y)) \\mid$$\n",
    "    \n",
    "    Where $f^{-1}(y) = y^2$. Applying this we get:\n",
    "    \n",
    "    $$p_y(y) = p_x(y^2) \\ \\mid \\frac{d}{dy} y^2 \\mid$$\n",
    "    \n",
    "    Taking the derivative and re-arranging terms for the final result:\n",
    "    \n",
    "    $$\\boxed{p_y(y) = 2y \\lambda \\exp(-\\lambda y^2), \\ \\ y \\geq 0}$$\n",
    "\n",
    "    <br>\n",
    "    \n",
    "    (b) What is the cdf, $F(y) = P(Y \\leq y)$? Verify that $F(0) = 0$ and $F(\\infty) = 1$.\n",
    "    \n",
    "    The cdf can be defined in terms of the pdf as seen in the lecture notes:\n",
    "    \n",
    "    $$F(x) = P(X \\leq x) = \\int_{-\\infty}^{x} p(t) dt$$\n",
    "    \n",
    "    Applying this to $p(y) = 2y \\lambda \\exp(-\\lambda y^2)$ and for $y \\geq 0$:\n",
    "    \n",
    "    $$F(y) = P(Y \\leq y) = \\int_{0}^{y} 2t \\lambda \\exp(-\\lambda t^2) \\ dt$$\n",
    "    \n",
    "    Taking the definite integral from 0 to y over t:\n",
    "    \n",
    "    $$F(y) = P(Y \\leq y) = 2t \\lambda \\exp(-\\lambda t^2) \\Big|_0^y$$\n",
    "    \n",
    "    $$F(y) = P(Y \\leq y) = -exp(-\\lambda y^2) -(-exp(0)$$\n",
    "    \n",
    "    $$\\boxed{F(y) = P(Y \\leq y) = 1 - exp(-\\lambda y^2), \\ \\ y \\geq 0}$$\n",
    "    \n",
    "    Finally we can verify that $F(0) = 0$ and $F(\\infty) = 1$:\n",
    "    \n",
    "    $$\\boxed{F(0) = P(Y \\leq 0) = 1 - exp(-\\lambda * 0) = 1 - 1 = 0}$$\n",
    "    \n",
    "    $$\\boxed{F(\\infty) = P(Y \\leq \\infty) = 1 - exp(-\\lambda * \\infty) = 1 - 0 = 1}$$\n",
    "    \n",
    "    <br>\n",
    "    \n",
    "    (c) What is the quantile function $F^{-1}$?\n",
    "    \n",
    "    The quantile function $F^{-1}$ is the inverse function of the cdf ([wiki](https://en.wikipedia.org/wiki/Quantile_function)). We will start with the cdf and find its inverse by isolating $y$:\n",
    "    \n",
    "    $$p = 1 - exp(- \\lambda y^2)$$\n",
    "    \n",
    "    $$1 - p = exp(- \\lambda y^2)$$\n",
    "    \n",
    "    $$ln(1 - p) = -\\lambda y^2$$\n",
    "    \n",
    "    $$\\frac{-ln(1 - p)}{\\lambda} = y^2$$\n",
    "    \n",
    "    $$y = \\sqrt{\\frac{-ln(1 - p)}{\\lambda}}$$\n",
    "    \n",
    "    $$\\boxed{F^{-1} = \\sqrt{\\frac{-ln(1 - p)}{\\lambda}}}$$\n",
    "    \n",
    "    (d) Compute the mean, E[Y], and variance, Var(Y).\n",
    "    \n",
    "    First we will start with the mean or E[Y] which is given by:\n",
    "    \n",
    "    $$E[Y] = \\int_{0}^{\\infty} y * (2y \\ \\lambda \\ exp(-\\lambda \\ y^2)) dy$$\n",
    "    \n",
    "    We will follow the hint and do integration by parts. Choosing $u = y$, $\\frac{dv}{dx} = 2y \\ \\lambda \\ exp(- \\lambda  \\ y^2)$, $\\frac{du}{dx} = 1$, and solving for v:\n",
    "    \n",
    "    $$v = \\int 2y \\ \\lambda exp(- \\lambda \\ y^2) = -exp(-\\lambda \\ y^2)$$\n",
    "    \n",
    "    With these four values, we can solve the original integral:\n",
    "    \n",
    "    $$E[Y] = (y * -exp(-\\lambda \\ y^2))\\Big|_0^\\infty - \\int_{0}^{\\infty} -exp(-\\lambda \\ y^2) dy$$\n",
    "    \n",
    "    $$E[Y] = 0 + \\frac{\\sqrt{\\pi}}{2\\sqrt{\\lambda}}$$\n",
    "    \n",
    "    $$\\boxed{E[Y] = \\frac{\\sqrt{\\pi}}{2\\sqrt{\\lambda}}}$$\n",
    "    \n",
    "    Next we will calculate $Var(Y)$ using the formula for continuous random variables ([wiki](https://en.wikipedia.org/wiki/Variance#Continuous_random_variable)):\n",
    "    \n",
    "    $$Var(Y) = \\int y^2 \\ p(y) \\ dy \\ - E[Y]^2$$\n",
    "    \n",
    "    $$Var(Y) = \\int_{0}^{\\infty} y^2 * (2y \\ \\lambda \\ exp(-\\lambda \\ y^2))  \\ dy \\ - E[Y]^2$$\n",
    "    \n",
    "    We will use integration by parts again. Choosing $u = y^2$, $\\frac{dv}{dx} = 2y \\ \\lambda \\ exp(- \\lambda  \\ y^2)$, $\\frac{du}{dx} = 2y$, and $v = -exp(-\\lambda \\ y^2)$.\n",
    "    \n",
    "    $$Var(Y) = (y^2 * -exp(-\\lambda \\ y^2))\\Big|_0^\\infty - \\int_{0}^{\\infty} -exp(-\\lambda \\ y^2) * (2y) dy - E[Y]^2$$\n",
    "    \n",
    "    Taking the integral:\n",
    "    \n",
    "    $$Var(Y) = 0 + \\frac{1}{\\lambda} - E[Y]^2$$\n",
    "    \n",
    "    Replacing the value of $E[Y]$ found earlier in the problem:\n",
    "    \n",
    "    $$Var(Y) = \\frac{1}{\\lambda} - (\\frac{\\sqrt{\\pi}}{2\\sqrt{\\lambda}})^2$$\n",
    "    \n",
    "    $$\\boxed{Var(Y) = \\frac{1}{\\lambda} - \\frac{\\pi}{4 \\lambda}}$$\n",
    "    \n",
    "    <br>\n",
    "    \n",
    "4. Given a realization $y_1, y_2, . . . , y_n$ from your random variable $Y$ in the previous problem, what is the maximum likelihood estimate for $\\lambda$?\n",
    "\n",
    "    We will assume that our sample is i.i.d. for our MLE estimate of $\\lambda$. Following the [lecture notes](http://www.cs.utah.edu/~fletcher/cs6190/lectures/MaximumLikelihoodEstimation.html), we will define the likelihood function $\\mathcal{L}(\\lambda)$ as such:\n",
    "    \n",
    "    $$\\mathcal{L}(\\lambda) = p_{y_1,...,y_n} \\ (y_1, y_2, ...., y_n ; \\lambda)$$\n",
    "    \n",
    "    The samples $y_i$ are independent of each other:\n",
    "    \n",
    "    $$\\mathcal{L}(\\lambda) = \\prod_{i = 1}^n p_{y_i} (y_i ; \\lambda)$$\n",
    "    \n",
    "    Apply the pdf $p(y)$ to each sample $y_i$:\n",
    "    \n",
    "    $$\\mathcal{L}(\\lambda) = \\prod_{i = 1}^n 2y_i \\lambda \\exp(-\\lambda y_i^2)$$\n",
    "    \n",
    "    Change the product into a sum inside the exponential:\n",
    "    \n",
    "    $$\\mathcal{L}(\\lambda) =\\prod_{i = 1}^n 2y_i \\lambda  \\ \\exp(-\\lambda \\sum_{i=1}^n y_i^2)$$\n",
    "     \n",
    "    Gives us the likelihood function we can work with to maximize. We will find the log-likelihood function and maximize that. Taking the natural log of the likelihood function:\n",
    "    \n",
    "    $$\\ell(\\lambda) = \\ln \\mathcal{L}(\\lambda) = ln(\\prod_{i = 1}^n 2y_i \\lambda \\ \\exp(-\\lambda \\sum_{i=1}^n y_i^2))$$\n",
    "    \n",
    "    Using $ln(ab) = ln(a) + ln(b)$:\n",
    "    \n",
    "    $$\\ell(\\lambda) = \\sum_{i = 1}^n \\ln(2y_i \\lambda) \\ + ln(\\exp(-\\lambda \\sum_{i=1}^n y_i^2))$$\n",
    "    \n",
    "    $$\\ell(\\lambda) = \\sum_{i = 1}^n \\ln(2y_i \\lambda) \\ - \\lambda \\sum_{i=1}^n y_i^2$$\n",
    "    \n",
    "    We will use the fact that the derivative of $\\ell$ will be zero at the maxima. Setting the derivative of $\\ell$ to zero and solving for $\\lambda$:\n",
    "    \n",
    "    $$0 = \\frac{d}{d \\lambda} (\\ell(\\lambda) = \\frac{d}{d \\lambda} \\sum_{i = 1}^n \\ln(2y_i \\lambda) \\ - \\lambda \\sum_{i=1}^n y_i^2)$$\n",
    "    \n",
    "    $$0 = \\frac{d}{d \\lambda} (\\sum_{i = 1}^n \\ln(2y_i \\lambda)) \\ - \\sum_{i=1}^n y_i^2$$\n",
    "    \n",
    "    $$0 = \\frac{n}{\\lambda} - \\sum_{i = 1}^n y_i^2$$\n",
    "    \n",
    "    Finally we isolate $\\lambda$:\n",
    "    \n",
    "    $$\\sum_{i = 1}^n y_i^2 = \\frac{n}{\\lambda}$$\n",
    "    \n",
    "    $$\\lambda = \\frac{n}{\\sum_{i = 1}^n y_i^2}$$\n",
    "    \n",
    "    This gives us our final MLE:\n",
    "    \n",
    "    $$\\boxed{\\hat \\lambda = \\frac{n}{\\sum_{i = 1}^n y_i^2}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding Part\n",
    "\n",
    "Recall that if $F$ is a cdf and $U \\sim Unif(0,1)$, then $Y = F^{-1}(U)$\n",
    "will be a random variable with cdf $F$. Write a function that uses this method\n",
    "to generate $n$ random numbers from the distribution of $Y$ in Problem 3 above\n",
    "($n$ and $\\lambda$ should be parameters to the function).\n",
    "\n",
    "(a) Generate 10,000 realizations of the random variable $Y$ with $\\lambda = 2$. <br>\n",
    "(b) Plot a histogram of the 10,000 realizations found in part (a). <br>\n",
    "(c) Use a lines command to plot the pdf $p(y)=2yλexp(−λy^2)$ on top. <br>\n",
    "(d) Compute the sample mean and variance of your 10,000 realizations. Do they roughly match the values for $E[Y]$ and $Var(Y)$ you calculated above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nG0xzAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11553ce80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample expectation:  0.6291757565515812\n",
      "Actual expectation:  0.6266570686577501\n",
      "\n",
      "Sample variance:  0.10766411381209821\n",
      "Actual variance:  0.10730091830127586\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "''' Uses the inverse transform sampling method to produce n samples.\n",
    "    Samples are taken from Y from problem 3 with lambda = lam. '''\n",
    "def generate_random_variables(n, lam):\n",
    "    random_variables = []\n",
    "    for i in range(n):\n",
    "        x = np.random.uniform(0, 1)\n",
    "        y = math.sqrt(-1 * (math.log(1 - x) / lam))\n",
    "        random_variables.append(y)\n",
    "    return random_variables\n",
    "\n",
    "''' Returns a list a pdf functions for a given list of y values and a given lambda. '''\n",
    "def pdfs(realizations, lam):\n",
    "    pdfs = []\n",
    "    for y in realizations:\n",
    "        pdf = 2 * y * lam * math.exp(-1 * lam * y * y)\n",
    "        pdfs.append(pdf)\n",
    "    return pdfs\n",
    "\n",
    "''' Returns the expectation of a collection of realizations '''\n",
    "def expectation(realizations):\n",
    "    sum = 0\n",
    "    for y in realizations:\n",
    "        sum = sum + y\n",
    "    return sum / len(realizations)\n",
    "\n",
    "''' Returns the variance of a collection of realizations '''\n",
    "def variance(realizations, exp):\n",
    "    sum = 0\n",
    "    for y in realizations:\n",
    "        sum = sum + math.pow((y - exp), 2)\n",
    "    return sum / len(realizations)\n",
    "\n",
    "# Generate 10,000 realizations with lambda = 2 (part a)\n",
    "realizations = generate_random_variables(10000, 2)\n",
    "\n",
    "# Compute the pdfs of the 10,0000 realizations\n",
    "pdf_col = pdfs(realizations, 2)\n",
    "\n",
    "# Visualize a histogram of the realizations (part b)\n",
    "plt.hist(realizations, density=True, zorder=0, color='#7CC2D6', histtype='bar', ec='black')\n",
    "\n",
    "# Visualize a line plot of the pdfs (part c)\n",
    "plt.scatter(realizations, pdf_col, color='black', s=10, zorder=1)\n",
    "plt.show()\n",
    "\n",
    "# Compute the mean of the realizations (part d)\n",
    "sample_exp = expectation(realizations)\n",
    "actual_exp = math.sqrt(math.pi) / (2 * math.sqrt(2))\n",
    "print(\"Sample expectation: \", sample_exp)\n",
    "print(\"Actual expectation: \", actual_exp)\n",
    "print()\n",
    "\n",
    "# Compute the variances of the realizations (part d)\n",
    "sample_var = variance(realizations, sample_exp)\n",
    "actual_var = 0.5 - (math.pi / 8)\n",
    "print(\"Sample variance: \", sample_var)\n",
    "print(\"Actual variance: \", actual_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) The sample mean and variance roughly match the values for E[Y] and Var(Y) in Problem 3.\n",
    "\n",
    "Now generate $20$ realizations from $Y$ with $\\lambda = 2$. Plot the log likelihood function for this data. Plot a vertical line at the maximum likelihood estimate for lambda (using the equation you got in Problem 4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1157efac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "''' Uses the inverse transform sampling method to produce n samples.\n",
    "    Samples are taken from Y from problem 3 with lambda = lam. '''\n",
    "def generate_random_variables(n, lam):\n",
    "    random_variables = []\n",
    "    for i in range(n):\n",
    "        x = np.random.uniform(0, 1)\n",
    "        y = math.sqrt(-1 * (math.log(1 - x) / lam))\n",
    "        random_variables.append(y)\n",
    "    return random_variables\n",
    "\n",
    "def log_likelihood(realizations, lam):\n",
    "    sum = 0\n",
    "    for y in realizations:\n",
    "        sum = sum + math.log(2 * y * lam) - (lam * y * y)\n",
    "    return sum\n",
    "\n",
    "def mle(realizations):\n",
    "    sum = 0\n",
    "    for y in realizations:\n",
    "        sum = sum + (y * y)\n",
    "    return len(realizations) / sum\n",
    "\n",
    "# Generate 20 realizations with lambda = 2\n",
    "realizations = generate_random_variables(20, 2)\n",
    "\n",
    "# Compute the log likelihood with lambda = 2 on the 20 samples\n",
    "log_like = log_likelihood(realizations, 2)\n",
    "\n",
    "# Visualize the log likelihood function for lambda = 2\n",
    "plt.axhline(y=log_like, color='red', linestyle='-')\n",
    "\n",
    "# Compute the MLE obtained from the samples\n",
    "estimate = mle(realizations)\n",
    "\n",
    "# Visualize the MLE\n",
    "plt.axhline(y=estimate, color='blue', linestyle='-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
