{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 0\n",
    "### Jake Pitkin\n",
    "**CS 6190: Probabilistic Modeling - Spring 2018**<br>\n",
    "**January 19th 2018**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Let $X$ and $Y$ be continuous, real-valued random variables. Prove the following: \n",
    "\n",
    "    (a) $E[[X|Y]] = E[X]$\n",
    "    \n",
    "    First we will use the hint and apply the definition of expectation for continuous random variables over Y.\n",
    "    \n",
    "    $$\\int_{-\\infty}^{\\infty} E[ X | Y ] \\  p_y(y) \\ dy$$\n",
    "    \n",
    "    Next apply the definition of conditional expectation from the lecture notes.\n",
    "    \n",
    "    $$\\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} x \\ p_x(x \\ | \\ y) \\ dx \\  p_y(y) \\ dy$$\n",
    "    \n",
    "    Using the definition of joint probability density over two random variables $X, Y$ which is $p(x, y) = p(x|y) * p(y)$.\n",
    "    \n",
    "    $$\\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} x \\ p(x,y) \\ dx \\ dy$$\n",
    "    \n",
    "    Now that we have the joint probability density of $X$ and $Y$, we take the marginal density of X from the lecture notes.\n",
    "    \n",
    "    $$\\int_{-\\infty}^{\\infty} x \\ p(x) \\ dx$$\n",
    "    \n",
    "    Finally the definition of expection of a continuous random variable is applied:\n",
    "    \n",
    "    $$\\int_{-\\infty}^{\\infty} x \\ p(x) \\ dx = E[X]$$\n",
    "    \n",
    "    Thus we have shown that $E[[X|Y]] = E[X]$.\n",
    "    <br><br>\n",
    "    \n",
    "    (b) $Var(X) = E[Var(X|Y)] + Var(E[X|Y])$\n",
    "    \n",
    "    For this proof I will be using the expanded definition of variance $Var(x) = E[X^2] - E[X]^2$ which is shown here [wiki](https://en.wikipedia.org/wiki/Variance#Definition).\n",
    "    \n",
    "    Following the hint, we will expand both the terms on the RHS using the above definition of variance. Expanding $E[Var(X|Y)]$:\n",
    "    \n",
    "    $$E[E[X^2|Y] - E[X|Y]^2] + Var(E[X|Y])$$\n",
    "    \n",
    "   And expanding next expanding $Var(E[X|Y])$:\n",
    "   \n",
    "   $$E[E[X^2|Y] - E[X|Y]^2] + E[E[X|Y]^2] - E[E[X|Y]]^2$$\n",
    "   \n",
    "   Next we will use the linearity of expectation from the lecture notes to get two like terms we can cancel out:\n",
    "   \n",
    "   $$E[E[X^2|Y]] - E[E[X|Y]^2] + E[E[X|Y]^2] - E[E[X|Y]]^2$$\n",
    "   \n",
    "   Canceling out like terms:\n",
    "   \n",
    "   $$E[E[X^2|Y]] - E[E[X|Y]]^2$$\n",
    "   \n",
    "   Finally we apply the result from part (a) to both parts of the equation:\n",
    "   \n",
    "   $$E[X^2] - E[X]^2$$\n",
    "   \n",
    "   This matches the expanded definition of $Var(x)$\n",
    "   \n",
    "   $$Var(x) = E[X^2] - E[X]^2$$\n",
    "   \n",
    "   Thus we have shown that $Var(X) = E[Var(X|Y)] + Var(E[X|Y])$. <br><br>\n",
    "   \n",
    "2. Consider random variables $X$ and $Y$ with joint pdf\n",
    "$$\\begin{equation*}\n",
    "p(x, y) =\n",
    "\\begin{cases}\n",
    "x + y \\qquad &\\text{for $0 \\leq x \\leq 1$, and $0 \\leq y \\leq 1$}\\\\\n",
    "0\\qquad &\\text{otherwise}\n",
    "\\end{cases}\n",
    "\\end{equation*}$$\n",
    "\n",
    "    (a) What is the marginal pdf $p(x)$?\n",
    "    \n",
    "    From the lecture notes the marginal pdf of $X$ is given by: \n",
    "    \n",
    "    $$p(x) = \\int_{a}^{b} p(x, y) \\ dy$$\n",
    "    \n",
    "    Applying this to our case to get the marginal pdf $p(x)$:\n",
    "    \n",
    "    $$p(x) = \\int_{0}^{1} x + y \\ dy$$\n",
    "    \n",
    "    $$p(x) = x * \\frac{y^2}{2} \\Big|_0^1$$\n",
    "    \n",
    "    $$\\boxed{p(x) = \\frac{x}{2}, \\ \\ \\ \\ 0 \\leq x \\leq 1}$$\n",
    "    \n",
    "    <br>\n",
    "    \n",
    "    (b) What is the conditional pdf $p(y | x)$?\n",
    "    \n",
    "    Given two random variables $X$ and $Y$, the conditional pdf is given by:\n",
    "    \n",
    "    $$p(y | x) = \\frac{p(y, x)}{p(x)}$$\n",
    "    \n",
    "    We are given $p(y, x)$ (same as $p(x, y)$) and we solved for $p(x)$ in part (a). Putting it together:\n",
    "    \n",
    "    $$p(y | x) = \\frac{x + y}{\\frac{x}{2}}$$\n",
    "    \n",
    "    $$\\boxed{p(y | x) = \\frac{2(x + y)}{x}, \\ \\ \\ \\ 0 \\leq x \\leq 1, \\ \\ 0 \\leq y \\leq 1}$$\n",
    "    \n",
    "    <br>\n",
    "    \n",
    "    (c) What is the conditional expectation $E[Y | X]$?\n",
    "    \n",
    "    Given two random variables $X$ and $Y$ where $X = x$, the conditional expectation is given by: \n",
    "    \n",
    "    $$E[Y | X = x] = \\int_{-\\infty}^{\\infty} y \\ p(y|x) \\ dy$$\n",
    "    \n",
    "    Using $p(y|x)$ from part (b), we can solve for $E[Y | X = x]$:\n",
    "    \n",
    "    $$E[Y | X = x] = \\int_{0}^{1} \\frac{2y(x+y)}{x} \\ dy$$\n",
    "    \n",
    "    $$E[Y | X = x] = 2 \\int_{0}^{1} \\frac{yx+ y^2}{x} \\ dy$$\n",
    "    \n",
    "    $$E[Y | X = x] = 2 * \\frac{\\frac{xy^2}{2} + \\frac{y^3}{3}}{x} \\Big|_0^1$$\n",
    "    \n",
    "    $$E[Y | X = x] = 2 * \\frac{\\frac{x}{2} + \\frac{1}{3}}{x}$$\n",
    "    \n",
    "    $$\\boxed{E[Y | X = x] = \\frac{x + \\frac{2}{3}}{x}, \\ \\ \\ \\ 0 \\leq x \\leq 1}$$\n",
    "    \n",
    "    <br>\n",
    "\n",
    "    (d) What is the covariance $Cov(X, Y)$?\n",
    "    \n",
    "    From the lecture notes the covariance of two random variables $X$ and $Y$ is given by:\n",
    "    \n",
    "    $$Cov(X, Y) = E[XY] - E[X]E[Y]$$\n",
    "    \n",
    "    We will solve for the three parts and put it together. First, we will solve for $E[XY]$ which is given by:\n",
    "    \n",
    "    $$E[XY] = \\int_{0}^{1} \\int_{0}^{1} xy \\ p(x, y) \\ dx  \\ dy$$\n",
    "    \n",
    "    $$E[XY] = \\int_{0}^{1} \\int_{0}^{1} x^2y + xy^2 \\ dx \\ dy$$\n",
    "    \n",
    "    Integrate by x first from 0 to 1 followed by integrating by y from 0 to 1:\n",
    "    \n",
    "    $$E[XY] = \\int_{0}^{1} \\frac{y}{3} + \\frac{y^2}{2} \\ dy$$\n",
    "    \n",
    "    $$E[XY] = \\frac{1}{3}$$\n",
    "    \n",
    "    Next we will solve for $E[X]$ using $p(x)$ from part (a):\n",
    "    \n",
    "    $$E[X] = \\int_{0}^{1} x \\ p(x) \\ dx$$\n",
    "    \n",
    "    $$E[X] = \\int_{0}^{1} \\frac{x^2}{2} dx$$\n",
    "    \n",
    "    $$E[X] = \\frac{1}{6}$$\n",
    "    \n",
    "    To solve for $E[Y]$ we need $p(y)$:\n",
    "    \n",
    "    $$p(y) = \\int_{0}^{1} x + y \\ dx$$\n",
    "    \n",
    "    $$p(y) = \\frac{y}{2}$$\n",
    "    \n",
    "    Then we solve for $E[Y]$:\n",
    "    \n",
    "    $$E[Y] = \\int_{0}^{1} y \\ p(y) \\ dx$$\n",
    "    \n",
    "    $$E[Y] = \\int_{0}^{1} \\frac{y^2}{2} dx$$\n",
    "    \n",
    "    $$E[Y] = \\frac{1}{6}$$\n",
    "    \n",
    "    Finally we put it all together to get $Cov(X, Y)$:\n",
    "    \n",
    "    $$Cov(X, Y) = E[XY] - E[X]E[Y]$$\n",
    "    \n",
    "    $$Cov(X, Y) = \\frac{1}{3} - \\frac{1}{36}$$\n",
    "    \n",
    "    $$\\boxed{Cov(X, Y) = \\frac{11}{36}, \\ \\ \\ \\ 0 \\leq x \\leq 1, \\ \\ 0 \\leq y \\leq 1}$$\n",
    "    \n",
    "    <br>\n",
    "    \n",
    "3. Let $X \\sim Exp(\\lambda)$, i.e., the exponential distribution with pdf\n",
    "$p(x) = \\lambda \\exp(-\\lambda x)$. Let $Y = \\sqrt{X}$.\n",
    "\n",
    "    (a) What is the density function $p(y)$?\n",
    "    \n",
    "    To determine $p(y)$, we will transform the random variable $X$ to $Y$ using the transformation function $f(x) = \\sqrt{x}$. A requirement is $f(x)$ must be a one-to-one function, which it is. We will use the transformation technique from the lecture notes:\n",
    "    \n",
    "    $$p_y(y) = p_x(f^{-1}(y)) \\ \\mid \\frac{d}{dy} (f^{-1}(y)) \\mid$$\n",
    "    \n",
    "    Where $f^{-1}(y) = y^2$. Applying this we get:\n",
    "    \n",
    "    $$p_y(y) = p_x(y^2) \\ \\mid \\frac{d}{dy} y^2 \\mid$$\n",
    "    \n",
    "    Taking the derivative and re-arranging terms for the final result:\n",
    "    \n",
    "    $$\\boxed{p_y(y) = 2y \\lambda \\exp(-\\lambda y^2), \\ \\ y \\geq 0}$$\n",
    "\n",
    "    <br>\n",
    "    \n",
    "    (b) What is the cdf, $F(y) = P(Y \\leq y)$? Verify that $F(0) = 0$ and $F(\\infty) = 1$.\n",
    "    \n",
    "    The cdf can be defined in terms of the pdf as seen in the lecture notes:\n",
    "    \n",
    "    $$F(x) = P(X \\leq x) = \\int_{-\\infty}^{x} p(t) dt$$\n",
    "    \n",
    "    Applying this to $p(y) = 2y \\lambda \\exp(-\\lambda y^2)$ and for $y \\geq 0$:\n",
    "    \n",
    "    $$F(y) = P(Y \\leq y) = \\int_{0}^{y} 2t \\lambda \\exp(-\\lambda t^2) \\ dt$$\n",
    "    \n",
    "    Taking the definite integral from 0 to y over t:\n",
    "    \n",
    "    $$F(y) = P(Y \\leq y) = 2t \\lambda \\exp(-\\lambda t^2) \\Big|_0^y$$\n",
    "    \n",
    "    $$F(y) = P(Y \\leq y) = -exp(-\\lambda y^2) -(-exp(0)$$\n",
    "    \n",
    "    $$\\boxed{F(y) = P(Y \\leq y) = 1 - exp(-\\lambda y^2), \\ \\ y \\geq 0}$$\n",
    "    \n",
    "    Finally we can verify that $F(0) = 0$ and $F(\\infty) = 1$:\n",
    "    \n",
    "    $$\\boxed{F(0) = P(Y \\leq 0) = 1 - exp(-\\lambda * 0) = 1 - 1 = 0}$$\n",
    "    \n",
    "    $$\\boxed{F(\\infty) = P(Y \\leq \\infty) = 1 - exp(-\\lambda * \\infty) = 1 - 0 = 1}$$\n",
    "    \n",
    "    <br>\n",
    "    \n",
    "    (c) What is the quantile function $F^{-1}$?\n",
    "    \n",
    "    The quantile function $F^{-1}$ is the inverse function of the cdf ([wiki](https://en.wikipedia.org/wiki/Quantile_function)). We will start with the cdf and find its inverse by isolating $y$:\n",
    "    \n",
    "    $$p = 1 - exp(- \\lambda y^2)$$\n",
    "    \n",
    "    $$1 - p = exp(- \\lambda y^2)$$\n",
    "    \n",
    "    $$ln(1 - p) = -\\lambda y^2$$\n",
    "    \n",
    "    $$\\frac{-ln(1 - p)}{\\lambda} = y^2$$\n",
    "    \n",
    "    $$y = \\sqrt{\\frac{-ln(1 - p)}{\\lambda}}$$\n",
    "    \n",
    "    $$\\boxed{F^{-1} = \\sqrt{\\frac{-ln(1 - p)}{\\lambda}}}$$\n",
    "    \n",
    "    (d) Compute the mean, E[Y], and variance, Var(Y).\n",
    "    \n",
    "    First we will start with the mean or E[Y] which is given by:\n",
    "    \n",
    "    $$E[Y] = \\int_{0}^{\\infty} y * (2y \\ \\lambda \\ exp(-\\lambda \\ y^2)) dy$$\n",
    "    \n",
    "    We will follow the hint and do integration by parts. Choosing $u = y$, $\\frac{dv}{dx} = 2y \\ \\lambda \\ exp(- \\lambda  \\ y^2)$, $\\frac{du}{dx} = 1$, and solving for v:\n",
    "    \n",
    "    $$v = \\int 2y \\ \\lambda exp(- \\lambda \\ y^2) = -exp(-\\lambda \\ y^2)$$\n",
    "    \n",
    "    With these four values, we can solve the original integral:\n",
    "    \n",
    "    $$E[Y] = (y * -exp(-\\lambda \\ y^2))\\Big|_0^\\infty - \\int_{0}^{\\infty} -exp(-\\lambda \\ y^2) dy$$\n",
    "    \n",
    "    $$E[Y] = 0 + \\frac{\\sqrt{\\pi}}{2\\sqrt{\\lambda}}$$\n",
    "    \n",
    "    $$\\boxed{E[Y] = \\frac{\\sqrt{\\pi}}{2\\sqrt{\\lambda}}}$$\n",
    "    \n",
    "    Next we will calculate $Var(Y)$ using the formula for continuous random variables ([wiki](https://en.wikipedia.org/wiki/Variance#Continuous_random_variable)):\n",
    "    \n",
    "    $$Var(Y) = \\int y^2 \\ p(y) \\ dy \\ - E[Y]^2$$\n",
    "    \n",
    "    $$Var(Y) = \\int_{0}^{\\infty} y^2 * (2y \\ \\lambda \\ exp(-\\lambda \\ y^2))  \\ dy \\ - E[Y]^2$$\n",
    "    \n",
    "    We will use integration by parts again. Choosing $u = y^2$, $\\frac{dv}{dx} = 2y \\ \\lambda \\ exp(- \\lambda  \\ y^2)$, $\\frac{du}{dx} = 2y$, and $v = -exp(-\\lambda \\ y^2)$.\n",
    "    \n",
    "    $$Var(Y) = (y^2 * -exp(-\\lambda \\ y^2))\\Big|_0^\\infty - \\int_{0}^{\\infty} -exp(-\\lambda \\ y^2) * (2y) dy - E[Y]^2$$\n",
    "    \n",
    "    Taking the integral:\n",
    "    \n",
    "    $$Var(Y) = 0 + \\frac{1}{\\lambda} - E[Y]^2$$\n",
    "    \n",
    "    Replacing the value of $E[Y]$ found earlier in the problem:\n",
    "    \n",
    "    $$Var(Y) = \\frac{1}{\\lambda} - (\\frac{\\sqrt{\\pi}}{2\\sqrt{\\lambda}})^2$$\n",
    "    \n",
    "    $$\\boxed{Var(Y) = \\frac{1}{\\lambda} - \\frac{\\pi}{4 \\lambda}}$$\n",
    "    \n",
    "    <br>\n",
    "    \n",
    "4. Given a realization $y_1, y_2, . . . , y_n$ from your random variable $Y$ in the previous problem, what is the maximum likelihood estimate for $\\lambda$?\n",
    "\n",
    "    We will assume that our sample is i.i.d. for our MLE estimate of $\\lambda$. Following the [lecture notes](http://www.cs.utah.edu/~fletcher/cs6190/lectures/MaximumLikelihoodEstimation.html), we will define the likelihood function $\\mathcal{L}(\\lambda)$ as such:\n",
    "    \n",
    "    $$\\mathcal{L}(\\lambda) = p_{y_1,...,y_n} \\ (y_1, y_2, ...., y_n ; \\lambda)$$\n",
    "    \n",
    "    The samples $y_i$ are independent of each other:\n",
    "    \n",
    "    $$\\mathcal{L}(\\lambda) = \\prod_{i = 1}^n p_{y_i} (y_i ; \\lambda)$$\n",
    "    \n",
    "    Apply the pdf $p(y)$ to each sample $y_i$:\n",
    "    \n",
    "    $$\\mathcal{L}(\\lambda) = \\prod_{i = 1}^n 2y_i \\lambda \\exp(-\\lambda y_i^2)$$\n",
    "    \n",
    "    Change the product into a sum inside the exponential:\n",
    "    \n",
    "    $$\\mathcal{L}(\\lambda) =\\prod_{i = 1}^n 2y_i \\lambda  \\ \\exp(-\\lambda \\sum_{i=1}^n y_i^2)$$\n",
    "     \n",
    "    Gives us the likelihood function we can work with to maximize. We will find the log-likelihood function and maximize that. Taking the natural log of the likelihood function:\n",
    "    \n",
    "    $$\\ell(\\lambda) = \\ln \\mathcal{L}(\\lambda) = ln(\\prod_{i = 1}^n 2y_i \\lambda \\ \\exp(-\\lambda \\sum_{i=1}^n y_i^2))$$\n",
    "    \n",
    "    Using $ln(ab) = ln(a) + ln(b)$:\n",
    "    \n",
    "    $$\\ell(\\lambda) = \\sum_{i = 1}^n \\ln(2y_i \\lambda) \\ + ln(\\exp(-\\lambda \\sum_{i=1}^n y_i^2))$$\n",
    "    \n",
    "    $$\\ell(\\lambda) = \\sum_{i = 1}^n \\ln(2y_i \\lambda) \\ - \\lambda \\sum_{i=1}^n y_i^2$$\n",
    "    \n",
    "    We will use the fact that the derivative of $\\ell$ will be zero at the maxima. Setting the derivative of $\\ell$ to zero and solving for $\\lambda$:\n",
    "    \n",
    "    $$0 = \\frac{d}{d \\lambda} (\\ell(\\lambda) = \\frac{d}{d \\lambda} \\sum_{i = 1}^n \\ln(2y_i \\lambda) \\ - \\lambda \\sum_{i=1}^n y_i^2)$$\n",
    "    \n",
    "    $$0 = \\frac{d}{d \\lambda} (\\sum_{i = 1}^n \\ln(2y_i \\lambda)) \\ - \\sum_{i=1}^n y_i^2$$\n",
    "    \n",
    "    $$0 = \\frac{n}{\\lambda} - \\sum_{i = 1}^n y_i^2$$\n",
    "    \n",
    "    Finally we isolate $\\lambda$:\n",
    "    \n",
    "    $$\\sum_{i = 1}^n y_i^2 = \\frac{n}{\\lambda}$$\n",
    "    \n",
    "    $$\\lambda = \\frac{n}{\\sum_{i = 1}^n y_i^2}$$\n",
    "    \n",
    "    This gives us our final MLE:\n",
    "    \n",
    "    $$\\boxed{\\hat \\lambda = \\frac{n}{\\sum_{i = 1}^n y_i^2}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding Part\n",
    "\n",
    "Recall that if $F$ is a cdf and $U \\sim Unif(0,1)$, then $Y = F^{-1}(U)$\n",
    "will be a random variable with cdf $F$. Write a function that uses this method\n",
    "to generate $n$ random numbers from the distribution of $Y$ in Problem 3 above\n",
    "($n$ and $\\lambda$ should be parameters to the function).\n",
    "\n",
    "(a) Generate 10,000 realizations of the random variable $Y$ with $\\lambda = 2$. <br>\n",
    "(b) Plot a histogram of the 10,000 realizations found in part (a). <br>\n",
    "(c) Use a lines command to plot the pdf $p(y)=2yλexp(−λy^2)$ on top. <br>\n",
    "(d) Compute the sample mean and variance of your 10,000 realizations. Do they roughly match the values for $E[Y]$ and $Var(Y)$ you calculated above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x107e4eba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample expectation:  0.6235831999503549\n",
      "Actual expectation:  0.6266570686577501\n",
      "\n",
      "Sample variance:  0.10752204401283577\n",
      "Actual variance:  0.10730091830127586\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "''' Uses the inverse transform sampling method to produce n samples.\n",
    "    Samples are taken from Y from problem 3 with lambda = lam. '''\n",
    "def generate_random_variables(n, lam):\n",
    "    random_variables = []\n",
    "    for i in range(n):\n",
    "        x = np.random.uniform(0, 1)\n",
    "        y = math.sqrt(-1 * (math.log(1 - x) / lam))\n",
    "        random_variables.append(y)\n",
    "    return random_variables\n",
    "\n",
    "''' Returns a list a pdf functions for a given list of y values and a given lambda. '''\n",
    "def pdfs(realizations, lam):\n",
    "    pdfs = []\n",
    "    for y in realizations:\n",
    "        pdf = 2 * y * lam * math.exp(-1 * lam * y * y)\n",
    "        pdfs.append(pdf)\n",
    "    return pdfs\n",
    "\n",
    "''' Returns the expectation of a collection of realizations '''\n",
    "def expectation(realizations):\n",
    "    sum = 0\n",
    "    for y in realizations:\n",
    "        sum = sum + y\n",
    "    return sum / len(realizations)\n",
    "\n",
    "''' Returns the variance of a collection of realizations '''\n",
    "def variance(realizations, exp):\n",
    "    sum = 0\n",
    "    for y in realizations:\n",
    "        sum = sum + math.pow((y - exp), 2)\n",
    "    return sum / len(realizations)\n",
    "\n",
    "# Generate 10,000 realizations with lambda = 2 (part a)\n",
    "realizations = generate_random_variables(10000, 2)\n",
    "\n",
    "# Compute the pdfs of the 10,0000 realizations\n",
    "pdf_col = pdfs(realizations, 2)\n",
    "\n",
    "# Visualize a histogram of the realizations (part b)\n",
    "plt.hist(realizations, density=True, zorder=0, color='#7CC2D6', bins='auto')\n",
    "\n",
    "# Visualize a line plot of the pdfs (part c)\n",
    "plt.scatter(realizations, pdf_col, color='black', s=10, zorder=1)\n",
    "plt.show()\n",
    "\n",
    "# Compute the mean of the realizations (part d)\n",
    "sample_exp = expectation(realizations)\n",
    "actual_exp = math.sqrt(math.pi) / (2 * math.sqrt(2))\n",
    "print(\"Sample expectation: \", sample_exp)\n",
    "print(\"Actual expectation: \", actual_exp)\n",
    "print()\n",
    "\n",
    "# Compute the variances of the realizations (part d)\n",
    "sample_var = variance(realizations, sample_exp)\n",
    "actual_var = 0.5 - (math.pi / 8)\n",
    "print(\"Sample variance: \", sample_var)\n",
    "print(\"Actual variance: \", actual_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) The sample mean and variance roughly match the values for E[Y] and Var(Y) in Problem 3.\n",
    "\n",
    "Now generate $20$ realizations from $Y$ with $\\lambda = 2$. Plot the log likelihood function for this data. Plot a vertical line at the maximum likelihood estimate for lambda (using the equation you got in Problem 4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD8CAYAAACVZ8iyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2wOWD5cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115808748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "''' Uses the inverse transform sampling method to produce n samples.\n",
    "    Samples are taken from Y from problem 3 with lambda = lam. '''\n",
    "def generate_random_variables(n, lam):\n",
    "    random_variables = []\n",
    "    for i in range(n):\n",
    "        x = np.random.uniform(0, 1)\n",
    "        y = math.sqrt(-1 * (math.log(1 - x) / lam))\n",
    "        random_variables.append(y)\n",
    "    return random_variables\n",
    "\n",
    "''' Returns the pdf for a given y and lam. '''\n",
    "def pdf(y, lam):\n",
    "    return 2 * y * lam * math.exp(-1 * lam * y * y)\n",
    "\n",
    "''' Returns the log likelihood for each t in ts over the realizations with lambda = lam. '''\n",
    "def log_likelihood(realizations, ts, lam):\n",
    "    log_likes = []\n",
    "    for t in ts:\n",
    "        sum = 0\n",
    "        for y in realizations:\n",
    "            sum = sum + math.log(pdf(t, y))\n",
    "        log_likes.append(sum)\n",
    "    return log_likes\n",
    "\n",
    "''' Returns the MLE over the realizations. '''\n",
    "def mle(realizations):\n",
    "    sum = 0\n",
    "    for y in realizations:\n",
    "        sum = sum + (y * y)\n",
    "    return len(realizations) / sum\n",
    "\n",
    "# Generate 20 realizations with lambda = 2\n",
    "realizations = generate_random_variables(20, 2)\n",
    "# Generate a point every 0.001 in the range [0, 4)\n",
    "ts = np.arange(0.001, 4, 0.001)\n",
    "\n",
    "# Compute the log likelihood with lambda = 2 on the 20 samples for each t\n",
    "log_likes = log_likelihood(realizations, ts, 2)\n",
    "\n",
    "# Visualize the log likelihood function over the 20 samples for each t\n",
    "plt.plot(ts, log_likes, color='red', linestyle='-')\n",
    "\n",
    "# Compute the MLE obtained from the samples\n",
    "estimate = mle(realizations)\n",
    "\n",
    "# Visualize the MLE\n",
    "plt.axvline(x=estimate, color='blue', linestyle='-')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
