{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1\n",
    "### Jake Pitkin\n",
    "**CS 6190: Probabilistic Modeling - Spring 2018**<br>\n",
    "**February 1st 2018**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$1$. **Expectation of sufficient statistics:** Consider a random variable $X$ from a continuous exponential family with _natural_ parameter $\\eta = (\\eta_1,...,\\eta_n)$. Recall that this means the pdf is of the form:\n",
    "\n",
    "$$p(x) = h(x) \\ exp(\\eta \\cdot T(x) - A(\\eta))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1a) Show that $E[T(X) \\ | \\ \\eta] = \\nabla \\ A(\\eta) = (\\frac{dA}{d\\eta_1},...,\\frac{dA}{d\\eta_d})$.\n",
    "\n",
    "Using the hint, we will start by applying the identity $\\int p(x) \\ dx = 1$:\n",
    "\n",
    "$$\\int h(x) \\ exp(\\eta \\cdot T(x) - A(\\eta)) \\ dx = 1$$\n",
    "\n",
    "Then we will take the derivative with respect to $\\eta$ on both sides using the chain rule:\n",
    "\n",
    "$$\\frac{d}{d\\eta} \\int h(x) \\ exp(\\eta \\cdot T(x) - A(\\eta)) \\ dx = 0$$\n",
    "\n",
    "$$\\int h(x) \\ exp(\\eta \\cdot T(x) - A(\\eta)) \\ \\eta^\\prime \\ T(x) - A^\\prime(\\eta) \\ dx = 0$$\n",
    "\n",
    "Substituting back in the definition of the pdf $p(x)$:\n",
    "\n",
    "$$\\int p(x) \\ \\eta^\\prime \\ T(x) - A^\\prime(\\eta) \\ dx = 0$$\n",
    "\n",
    "Taking the definition of expectation of $T(x)$:\n",
    "\n",
    "$$E[T(x)] \\ \\eta^\\prime - A^\\prime(\\eta) = 0$$\n",
    "\n",
    "Re-arranging terms:\n",
    "\n",
    "$$E[T(x)] = \\frac{A^\\prime(\\eta)}{\\eta^\\prime} = \\frac{dA}{d\\eta}$$\n",
    "\n",
    "Thus given a _natural_ parameter $\\eta = (\\eta_1,...,\\eta_n)$, we have shown the expecation of $T(X)$ is:\n",
    "\n",
    "$$E[T(X)\\ | \\ \\eta] = (\\frac{dA}{d\\eta_1},...,\\frac{dA}{d\\eta_d}) = \\nabla \\ A(\\eta)$$\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "(1b) Verify this formula works for the Gaussian distribution with unknown mean, $\\mu$, and known variance, $\\sigma^2$.\n",
    "\n",
    "From [wikipedia](https://en.wikipedia.org/wiki/Exponential_family) we have the following for the Gaussian distribution with unknown mean and known variance:\n",
    "\n",
    "$$A(\\eta) = \\frac{\\eta^2}{2} \\qquad \\eta = \\frac{\\mu}{\\sigma} \\qquad T(x) = \\frac{x}{\\sigma}$$\n",
    "\n",
    "First will take the derivative of $A(\\eta)$ with respect to $\\eta$:\n",
    "\n",
    "$$\\frac{dA}{d\\eta}\\frac{\\eta^2}{2} = \\eta = \\frac{\\mu}{\\sigma}$$\n",
    "\n",
    "Then we will take the expectation of $T(x)$ for the Gaussian:\n",
    "\n",
    "$$E[T(x)] = \\int T(x) \\ p(x) \\ dx$$\n",
    "\n",
    "$$E[T(x)] = \\int \\frac{x}{\\sigma} \\ p(x) \\ dx$$\n",
    "\n",
    "$$E[T(x)] = \\frac{1}{\\sigma} \\int x \\ p(x) \\ dx$$\n",
    "\n",
    "We know the expecation of the Gaussian distrobution is the mean $\\mu$ from [wikipedia](https://en.wikipedia.org/wiki/Normal_distribution):\n",
    "\n",
    "$$E[T(x)] = \\frac{\\mu}{\\sigma}$$\n",
    "\n",
    "Thus we have shown $E[T(x)] = \\frac{\\mu}{\\sigma} = A(\\eta)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$2$. **Noninformative priors for the Poisson distribution:** Let $X \\sim Pois(\\lambda)$. Recall the pmf for the Poisson is\n",
    "\n",
    "$$P(X = k; \\lambda) = \\frac{\\lambda^k e^{-\\lambda}}{k!}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2a) Rewrite the above pmf in exponential family form. What is the natural parameter? What is the sufficient statistic?\n",
    "\n",
    "We will start by using the trick seen in class of taking the $log$ followed by the $exponential$ of both sides:\n",
    "\n",
    "$$p(x) = \\frac{\\lambda^k e^{-\\lambda}}{x!}$$\n",
    "\n",
    "$$log(p(x)) = log(\\frac{\\lambda^k e^{-\\lambda}}{x!})$$\n",
    "\n",
    "$$log(p(x)) = log(\\lambda^x) + log(e^{-\\lambda}) - log(x!)$$\n",
    "\n",
    "$$log p(x) = x log(\\lambda) - \\lambda - log(x!)$$\n",
    "\n",
    "Taking the $exponential$ of both sides:\n",
    "\n",
    "$$p(x) = exp(x log(\\lambda) - \\lambda - log(x!))$$\n",
    "\n",
    "$$p(x) = \\frac{1}{x!} exp(log(\\lambda) \\cdot x - \\lambda)$$\n",
    "\n",
    "With the pmf in a similar form to the exponental family, we can see the components:\n",
    "\n",
    "$$h(x) = \\frac{1}{x!} \\qquad \\eta = log(\\lambda) \\qquad T(x) = x \\qquad A(\\eta) = e^\\lambda$$\n",
    "\n",
    "With the natural parameter being $log(\\lambda)$ and the sufficient statistic being $x$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2b) Give at least two different options for noninformative priors for $p(\\lambda)$.\n",
    "\n",
    "Two options for noninformative priors for $p(\\lambda)$ are Jeffrey's Prior and the Uniform distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2c) What are the resulting posteriors for your two options? Are they proper (i.e., can they be normalized?)\n",
    "\n",
    "**Jeffrey's Prior:**\n",
    "\n",
    "First we will calculate the Jeffrey's Prior for the Poisson distribution which is given by:\n",
    "\n",
    "$$p(\\lambda) = \\sqrt{I(\\lambda)} = \\sqrt{- E[\\frac{d^2}{d\\lambda^2} \\ log \\ p(x \\ | \\ \\lambda) \\ | \\lambda]}$$\n",
    "\n",
    "We will solve for the second derivative of the log-likelihood function first:\n",
    "\n",
    "$$p(x \\ | \\ \\lambda) = \\prod_{i = 1}^n \\frac{\\lambda^{x_i} \\ exp(-\\lambda)}{x_i!}$$\n",
    "\n",
    "$$log(p(x \\ | \\ \\lambda)) = \\sum_{i = 1}^n x_i log(\\lambda) - n\\lambda - \\sum_{i = 1}^n log(x_i!)$$\n",
    "\n",
    "Taking the first derivative with respect to $\\lambda$:\n",
    "\n",
    "$$\\frac{d \\ log(p(x \\ | \\ \\lambda))}{d \\lambda} = \\frac{\\sum_{i = 1}^n x_i}{\\lambda} - n$$\n",
    "\n",
    "Taking the second derivative with respect to $\\lambda$:\n",
    "\n",
    "$$\\frac{d^2 \\ log(p(x \\ | \\ \\lambda))}{d^2 \\lambda} = -\\frac{\\sum_{i = 1}^n x_i}{\\lambda^2}$$\n",
    "\n",
    "Next we take the expectation (recall $\\lambda$ is the mean):\n",
    "\n",
    "$$E\\Big[-\\frac{\\sum_{i = 1}^n x_i}{\\lambda^2} \\ | \\ \\lambda \\Big] = \\frac{-n\\lambda}{\\lambda^2} = \\frac{-n}{\\lambda}$$\n",
    "\n",
    "With this we can calculate Jeffrey's Prior for the Poisson distribution:\n",
    "\n",
    "$$p(\\lambda) = \\sqrt{-(\\frac{-n}{\\lambda})} \\propto \\frac{1}{\\sqrt{\\lambda}}$$\n",
    "\n",
    "Finally, we have the likelihood and prior so we can calculate the posterior:\n",
    "\n",
    "$$p(\\lambda \\ | \\ x) = p(x \\ | \\ \\lambda) * p(\\lambda)$$\n",
    "\n",
    "$$p(\\lambda \\ | \\ x) = \\prod_{i = 1}^n \\frac{\\lambda^{x_i} \\ exp(-\\lambda)}{x_i!} * \\frac{1}{\\sqrt{\\lambda}}$$\n",
    "\n",
    "$$p(\\lambda \\ | \\ x) = \\big(\\prod_{i = 1}^n \\frac{1}{x_i !}\\big) \\ \\lambda^{\\sum_{i = 1}^n x_i} \\ exp(-\\lambda \\ n) \\ \\lambda^{-1/2}$$\n",
    "\n",
    "Removing terms that are constant in respect to $\\lambda$ and combining terms:\n",
    "\n",
    "$$p(\\lambda \\ | \\ x) = \\big(\\prod_{i = 1}^n \\frac{1}{x_i !}\\big) \\ \\lambda^{\\sum_{i = 1}^n x_i} \\ exp(-\\lambda \\ n) \\ \\lambda^{-1/2} \\propto \\lambda^{\\sum_{i = 1}^n x_i} \\ exp(-\\lambda \\ n) \\ \\lambda^{-1/2}$$\n",
    "\n",
    "$$p(\\lambda \\ | \\ x) = \\lambda^{\\sum_{i = 1}^n x_i - 1/2} \\ exp(-\\lambda \\ n)$$\n",
    "\n",
    "This is a Gamma distribution (where $\\alpha = \\sum^n x_i + 1/2, \\ \\beta = n$) which is proper:\n",
    "\n",
    "$$p(\\lambda \\ | \\ x) = \\lambda^{\\sum_{i = 1}^n x_i - 1/2} \\ exp(-\\lambda \\ n) = Gamma(\\lambda; \\alpha, \\beta)$$\n",
    "\n",
    "**Uniform Distribution:**\n",
    "\n",
    "With the uniform prior, every value of $\\lambda$ has equal probablity. This is ill defined on $[-\\infty, \\infty]$ but we will be approximate to use it as a prior.\n",
    "\n",
    "$$p(\\lambda \\ | \\ x) = p(x \\ | \\ \\lambda) * p(\\lambda)$$\n",
    "\n",
    "$$p(\\lambda \\ | \\ x) = \\prod_{i = 1}^n \\frac{\\lambda^{x_i} \\ exp(-\\lambda)}{x_i!} * 1$$\n",
    "\n",
    "$$p(\\lambda \\ | \\ x) = \\Big(\\prod_{i = 1}^n \\frac{1}{x_i !}\\big) \\ \\lambda^{\\sum_{i = 1}^n x_i} \\ exp(-\\lambda \\ n)$$\n",
    "\n",
    "Removing terms that are constant in respect to $\\lambda$:\n",
    "\n",
    "$$p(\\lambda \\ | \\ x) = \\Big(\\prod_{i = 1}^n \\frac{1}{x_i !}\\big) \\ \\lambda^{\\sum_{i = 1}^n x_i} \\ exp(-\\lambda \\ n)   \\propto \\lambda^{\\sum_{i = 1}^n x_i} \\ exp(-\\lambda \\ n)$$\n",
    "\n",
    "$$p(\\lambda \\ | \\ x) = \\lambda^{\\sum_{i = 1}^n x_i} \\ exp(-\\lambda \\ n)$$\n",
    "\n",
    "This is a Gamma distribution (where $\\alpha = \\sum^n x_i + 1, \\ \\beta = n$) which is proper:\n",
    "\n",
    "$$p(\\lambda \\ | \\ x) = \\lambda^{\\sum_{i = 1}^n x_i} \\ exp(-\\lambda \\ n) = Gamma(\\lambda; \\alpha, \\beta)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$3$. **Non-conjugate priors:** Let $X_i$ be from a Gaussian with known variance $\\sigma^2$ and mean $\\mu$ with _uniform prior_, i.e.,\n",
    "\n",
    "$$\\mu \\sim Unif(a, b)$$\n",
    "$$X_i \\sim N(\\mu, \\sigma^2)$$\n",
    "\n",
    "What is the posterior pdf, $p(\\mu \\ | \\ x_1,...,x_n;\\sigma^2, a, b$)?\n",
    "\n",
    "Starting with the uniform prior:\n",
    "\n",
    "$$p(\\mu; a, b) = \\frac{1}{b-a}$$\n",
    "\n",
    "And the likelihood of the Gaussian distribution with a known variance:\n",
    "\n",
    "$$L(x_1, ... , x_n | \\mu) = \\prod_{i=1}^n \\frac{1}{\\sqrt{2\\pi\\sigma^2}} exp\\big(\\frac{-(x_i - \\mu)^2}{2\\sigma^2}\\big)$$\n",
    "\n",
    "$$L(x_1, ... , x_n | \\mu) = \\Big(\\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\Big)^n exp\\big(\\frac{-\\sum_{i=1}^n(x_i - \\mu)^2}{2\\sigma^2}\\big)$$\n",
    "\n",
    "$$L(x_1, ... , x_n | \\mu) = (2\\pi\\sigma^2)^{-\\frac{n}{2}} \\ exp\\big(\\frac{-1}{2\\sigma^2} \\sum_{i=1}^n (x_i - \\mu)^2\\big)$$\n",
    "\n",
    "Combine the prior and the likelihood:\n",
    "\n",
    "$$$L(x_1, ... , x_n | \\mu) \\ p(\\mu; a, b) \\ (2\\pi\\sigma^2)^{-\\frac{n}{2}} \\ exp\\big(\\frac{-1}{2\\sigma^2} \\sum_{i=1}^n (x_i - \\mu)^2\\big) \\ \\frac{1}{b-a}$$\n",
    "\n",
    "Add a normalizing factor to get the posterior:\n",
    "\n",
    "$$p(\\mu \\ | \\ x_1, ... , x_n; \\sigma^2, a, b) = \\frac{(2\\pi\\sigma^2)^{-\\frac{n}{2}} \\ exp\\big(\\frac{-1}{2\\sigma^2} \\sum_{i=1}^n (x_i - \\mu)^2\\big) \\  \\frac{1}{b-a}}{\\int_{a}^{b} (2\\pi\\sigma^2)^{-\\frac{n}{2}} \\ exp\\big(\\frac{-1}{2\\sigma^2} \\sum_{i=1}^n (x_i - \\mu)^2\\big) \\  \\frac{1}{b-a} d\\mu}$$\n",
    "\n",
    "Move terms constant in $\\mu$ outside the integral:\n",
    "\n",
    "$$p(\\mu \\ | \\ x_1, ... , x_n; \\sigma^2, a, b) = \\frac{(2\\pi\\sigma^2)^{-\\frac{n}{2}} \\ exp\\big(\\frac{-1}{2\\sigma^2} \\sum_{i=1}^n (x_i - \\mu)^2\\big) \\  \\frac{1}{b-a}}{(2\\pi\\sigma^2)^{-\\frac{n}{2}} \\ \\frac{1}{b-a} \\int_{a}^{b}  exp\\big(\\frac{-1}{2\\sigma^2} \\sum_{i=1}^n (x_i - \\mu)^2\\big) d\\mu}$$\n",
    "\n",
    "Cancel out like terms in the numerator and the denominator:\n",
    "\n",
    "$$p(\\mu \\ | \\ x_1, ... , x_n; \\sigma^2, a, b) = \\frac{exp\\big(\\frac{-1}{2\\sigma^2} \\sum_{i=1}^n (x_i - \\mu)^2\\big)}{\\int_{a}^{b}  exp\\big(\\frac{-1}{2\\sigma^2} \\sum_{i=1}^n (x_i - \\mu)^2\\big) d\\mu}$$\n",
    "\n",
    "As the hint indicates, this integral is tough and we will stop here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Coding Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$4$. Use a conjuate prior $(\\mu_j, \\sigma_j^2) \\sim N-IG(0, 10^{-6}, 10^{-6}, 10^{-6})$, independently for each group $j$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
